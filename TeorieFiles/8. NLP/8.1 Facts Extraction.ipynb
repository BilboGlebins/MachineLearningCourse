{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://proglib.io/p/fun-nlp/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facts extraction pipeline\n",
    "\n",
    "Рассмотрим типичный процесс извлечения фактов из текста на примере вот такого отрывка:\n",
    "\n",
    "> London is the capital and most populous city of England and the United Kingdom. Standing on the River Thames in the south east of the island of Great Britain, London has been a major settlement for two millennia. It was founded by the Romans, who named it Londinium.\n",
    "\n",
    "Чтобы извлечь факты нам потребуется проделать следующие шаги:\n",
    "\n",
    "## Шаг 1. Выделить предложения\n",
    "\n",
    "Как правило, каждое предложение содержит законченную мысль или идею. В то же время, проще научить понимать компьютер единственное предложение, а не целый параграф. Можно было бы просто разделять текст по определенным знакам препинания. Но современные NLP пайплайны имеют в запасе более сложные методы, подходящие даже для работы с неформатированными фрагментами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Выполнить токенцизацию\n",
    "\n",
    "Далее мы должны разделить предложения на состовные части - токены. В данном случае, токенами будут слова и знаки препинания.\n",
    "\n",
    "> London is the capital and most populous city of England and the United Kingdom.\n",
    "\n",
    "После токенизации становится `['London', 'is', 'the', 'capital', 'and', 'most', 'populous', 'city', 'of', 'England', 'and', 'the', 'United', 'Kingdom', '.']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Определить части речи\n",
    "\n",
    "Теперь посмотрим на каждый токен и постараемся угадать, какой частью речи он является: существительным, глаголом, прилагательным или чем-то другим. Зная роль каждого слова в предложении, можно понять его общий смысл. Для этого необходима модель, обученная на корпусе текстов, в данном случае, английского языка. Модель пытается определить, какой частью речи является каждый отдельно взятый токен. Причем для определения используется не единственные токен, а 1-3 соседних токена.\n",
    "\n",
    "Такие модели имеют исключительно статистическую подоплёку, поэтому говорить о том, что модель \"понимает\" смысл слов, чтобы определить часть речь - ну такое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4. Выполнить лемматизацию\n",
    "\n",
    "Лемматизация - это процесс нахождения *основной формы* слова. Например, глаголы прошедшего времени превратить в инфинитивы. Леммой существительного, использованного в тексте во множественном числе, будет являться то же существительное, только в единственном числе. Лемматизация, так же, делается при помощи модели, обученной на корпусе языка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 5. Выделить стоп-слова\n",
    "\n",
    "Теперь мы хотим определить важность каждого слова в предложении. В английском очень много вспомогательных слов, например, «and», «the», «a». При статистическом анализе текста эти токены создают много шума, так как появляются чаще, чем остальные. Некоторые NLP пайплайны отмечают их как стоп-слова и отсеивают перед подсчетом количества. \n",
    "\n",
    "Для обнаружения стоп-слов обычно используются готовые таблицы. Однако нет единого стандартного списка, подходящего в любой ситуации. Игнорируемые токены могут меняться, все зависит от особенностей проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 6. Распарсить зависимости\n",
    "Теперь необходимо установить взаимосвязь между словами в предложении. Это называется парсингом зависимостей. Конечная цель этого шага – построение дерева, в котором каждый токен имеет единственного родителя. Корнем может быть главный глагол.\n",
    "\n",
    "Нужно не только определить родителя, но и установить тип связи между двумя словами:\n",
    "<center><img src='img/dependencies.png'></center>\n",
    "\n",
    "Парсинг зависимостей так же выполняется при помощи моделей. По состоянию на 2016 год лучшим парсером был Гугловский ParseySaurus. Мы же воспользуемся spaCy.\n",
    "\n",
    "## Шаг 6'. Сгруппировать существительные:\n",
    "*NB: Данный шаг не является обязательным, однако стоит вспомнить о нём, если вместо максимально подробной информации о словах мы стремимся извлечь законченные идеи.*\n",
    "\n",
    "\n",
    "Иногда имеет смысл сгруппировать токены, которые относятся к одной и той же идее или вещи. Мы можем использовать полученное дерево парсинга, чтобы автоматически объединить такие слова.\n",
    "\n",
    "Вместо токенизации по словам:\n",
    "<center><img src='img/before.png'></center>\n",
    "\n",
    "Группировкой существительных можно добиться повышения плотности смысловой нагрузки на токен:\n",
    "<center><img src='img/after.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 7. Распознавать именованные сущности (Named Entity Recognition, NER):\n",
    "\n",
    "Цель распознавания именованных сущностей – обнаружить такие существительные и связать их с реальными концепциями. Делается это снова при помощи моделей, обученных на корпусах текстов, где сущности уже размечены. После обработки каждого токена NER-моделью наше предложение будет выглядеть вот так:\n",
    "\n",
    "<center><img src='img/NER.png'></center>\n",
    "\n",
    "NER-системы не просто просматривают словари. Они анализируют контекст токена в предложении и используют статистические модели, чтобы угадать какой объект он представляет. Хорошие NER-системы способны отличить актрису Brooklyn Decker от города Brooklyn.\n",
    "\n",
    "Большинство NER-моделей распознают следующие типы объектов:\n",
    "\n",
    "- Имена людей\n",
    "- Названия компаний\n",
    "- Географические обозначения (и физические, и политические)\n",
    "- Продукты\n",
    "- Даты и время\n",
    "- Денежные суммы\n",
    "- События"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 8. Разрешить кореференции\n",
    "\n",
    "Теперь выйдем за пределы одного предложения. Вот мы распарсили предложения, распознали сущности в предложениях:\n",
    "\n",
    "> London has been a major settlement for two millennia. It was founded by the Romans, who named it Londinium.\n",
    "\n",
    "А теперь посмотрим на второе предложение. \n",
    "\n",
    "> **It** was founded by the Romans, who named **it** Londinium\n",
    "\n",
    "**Оно** было основано римлянами. Это предложение не содержит информацию о том, что это за **оно**. А вот предыдущее содержит. Чтобы извлечь факт \"Лондон был основан римлянами\" придётся связать предложение с предыдущим. Такой процесс называется *разрешением кореференций*. \n",
    "\n",
    "Формальное определение: *разрешением кореференции называется отслеживание местоимений в предложениях с целью выбрать все слова, относящиеся к одной сущности*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог\n",
    "\n",
    "В итоге имеем такой пайплайн:\n",
    "1. Сегментация предложений\n",
    "1. Токенизация\n",
    "1. Определение частей речи\n",
    "1. Лемматизация\n",
    "1. Выделение стоп-слов\n",
    "1. Парсинг зависимостей (+ группировка существительных)\n",
    "1. Распознование именованных сущностей\n",
    "1. Разрешение кореференций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Имплементация на python\n",
    "\n",
    "NLP в Python представлен библиотекой `spacy`. Два других инструмента `textacy` для извлечения фактов и `neuralcoref` для разрешения кореференций являются надстройками для `spacy`.\n",
    "\n",
    "Установим библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy==2.0.11\n",
    "# !pythom -m spacy download en_core_web_md \n",
    "\n",
    "# !pip install textacy\n",
    "\n",
    "# !pip install neuralcoref\n",
    "# !pip install https://github.com/huggingface/neuralcoref-models/releases/download/en_coref_md-3.0.0/en_coref_md-3.0.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Загрузка английской NLP-модели\n",
    "engine = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим пайплайн модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tagger', <spacy.pipeline.Tagger object at 0x7f781e0380f0>)\n",
      "('parser', <spacy.pipeline.DependencyParser object at 0x7f790d27b048>)\n",
      "('ner', <spacy.pipeline.EntityRecognizer object at 0x7f7982224c50>)\n"
     ]
    }
   ],
   "source": [
    "for part in engine.pipeline:\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Tagger` выделяет части речи и проводит лемматизацию\n",
    "- `Parser` парсит зависимости\n",
    "- `ner` выделяет именованные сущности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London (GPE)\n",
      "England (GPE)\n",
      "the United Kingdom (GPE)\n",
      "the River Thames (FAC)\n",
      "Great Britain (GPE)\n",
      "London (GPE)\n",
      "two millennia (DATE)\n",
      "Romans (NORP)\n",
      "Londinium (PERSON)\n"
     ]
    }
   ],
   "source": [
    "# Текст для анализа\n",
    "text = \"\"\"London is the capital and most populous city of England and \n",
    "the United Kingdom.  Standing on the River Thames in the south east \n",
    "of the island of Great Britain, London has been a major settlement \n",
    "for two millennia. It was founded by the Romans, who named it Londinium.\n",
    "\"\"\"\n",
    "\n",
    "# Обработка\n",
    "doc = engine(text)\n",
    "\n",
    "# Посмотрим, какие сущности выделила модель:\n",
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категории сущностей, распознаные NPE-движком из spacy:\n",
    "\n",
    "- `GPE` - Countries, cities, states.\n",
    "- `FAC` - Buildings, airports, highways, bridges, etc.\n",
    "- `DATE` - Absolute or relative dates or periods.\n",
    "- `NORP` - Nationalities or religious or political groups.\n",
    "- `PERSON` - People, including fictional.\n",
    "\n",
    "С полным списком категорий [можно ознакомиться здесь](https://spacy.io/usage/linguistic-features#entity-types)\n",
    "\n",
    "Теперь извлечём факты. Для этого нам потребуется модуль `extract` библиотеки `textacy` и его функция `semistructured_statements`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся развёрнутым текстом\n",
    "\n",
    "text = \"\"\"London is the capital of Great Britain, its political, economic and cultural centre. It's one of the largest cities in the world. Its population is more than million people. London is situated on the river Thames. The city is very old and beautiful. It was founded more than two thousand years ago. Traditionally London is divided into several parts: the City, the West End, the East End and Westminster. The City is the oldest part of London, its financial and business centre. The heart of the City is the Stock Exchange. Westminster is the most important part of the capital. It's the administrative centre. The Houses of Parliament, the seat of the British Government, are there. It's a very beautiful building with two towers and a very big clock called Big Ben. Big Ben is really the bell which strikes every quarter of an hour. Opposite the Houses of Parliament is Westminster Abbey. It's a very beautiful church built over 900 years ago. The tombs of many great statesmen, scientists and writers are there.\n",
    "\n",
    "To the west of Westminster is West End. Here we find most of the big shops, hotels, museums, art galleries, theatres and concert halls. Picadilly Circus is the heart of London's West End. In the West End there are wide streets with beautiful houses and many parks, gardens and squares. To the east of Westminster is the East End, an industrial district of the capital. There are no parks or gardens in the East End and you can't see many fine houses there. Most of the plants and factories are situated there. London has many places of interest. One of them is Buckingham Palace. It's the residence of the Queen. The English are proud of Trafalgar Square, which was named so in memory of the victory at the battle. There in 1805 the English fleet defeated the fleet of France and Spain. The last place of interest I should like to mention, is the British Museum, the biggest museum in London. The museum is famous for its library -one of the richest in the world.\n",
    "\n",
    "All London's long-past history is told by its streets. There are many streets in London which are known all over the\" world. Among them Oxford Street, Downing Street and a lot of others can be mentioned. And tourists are usually attracted not only by the places of interest but by the streets too. In conclusion I should say if you are lucky enough to find yourself in London some day you will have a lot to see and enjoy there.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy.extract as extract\n",
    "\n",
    "engine = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London / is / the capital of Great Britain, its political, economic and cultural centre\n"
     ]
    }
   ],
   "source": [
    "# Анализ\n",
    "doc = engine(text)\n",
    " \n",
    "# Извлечение фактов со словом London\n",
    "statements = extract.semistructured_statements(doc, \"London\")\n",
    "  \n",
    "for statement in statements:\n",
    "    subject, verb, fact = statement\n",
    "    print(f\"{subject} / {verb} / {fact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь выполним разрешение кореференций. Для этого потребуется `neuralcoref` и одна из обученных на нём моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_coref_md\n",
    "import textacy.extract as extract\n",
    "\n",
    "neural_engine = en_coref_md.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на пайплайн новой модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tagger', <spacy.pipeline.Tagger object at 0x7f5ec2139198>)\n",
      "('parser', <spacy.pipeline.DependencyParser object at 0x7f5ec21eec50>)\n",
      "('ner', <spacy.pipeline.EntityRecognizer object at 0x7f5ec21ee8e0>)\n",
      "('neuralcoref', <en_coref_md.neuralcoref.neuralcoref.NeuralCoref object at 0x7f5e52122ac8>)\n"
     ]
    }
   ],
   "source": [
    "for part in neural_engine.pipeline:\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Она отличается компонентом `neuralcoref` который отвечает за разрешение кореференции (напоминаю, связывание местоимений с сущностями, упомянутыми ранее). Процесс обработки текста выполняетс точно так же:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = neural_engine(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем посмотреть все найденные кореференции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[London: [London, London, The city, It, London, The City, London, its, the City],\n",
       " Great Britain: [Great Britain, Great Britain],\n",
       " Londons: [Londons, It, Its],\n",
       " Westminster: [Westminster, Westminster, It],\n",
       " Big Ben: [Big Ben, Big Ben],\n",
       " Opposite the Houses of Parliament: [Opposite the Houses of Parliament, It],\n",
       " West End: [West End, West End, the West End],\n",
       " London: [London, London],\n",
       " the East End: [the East End, the East End],\n",
       " many places of interest: [many places of interest, them],\n",
       " the British Museum, the biggest museum in London: [the British Museum, the biggest museum in London, The museum, its],\n",
       " London: [London, London, London, London],\n",
       " All London's long-past history: [All London's long-past history, its],\n",
       " its streets: [its streets, the streets],\n",
       " many streets in London which are known all over the\" world: [many streets in London which are known all over the\" world, them]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А так же версию текста, где местоимения уже заменены соответствующими сущностями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'London is the capital of Great Britain, London political, economic and cultural centre. London\\'s one of the largest cities in the world. London population is more than million people. London is situated on the river Thames. London is very old and beautiful. London was founded more than two thousand years ago. Traditionally London is divided into several parts: the City, the West End, the East End and Westminster. London is the oldest part of London, London financial and business centre. The heart of London is the Stock Exchange. Westminster is the most important part of the capital. Westminster\\'s the administrative centre. The Houses of Parliament, the seat of the British Government, are there. It\\'s a very beautiful building with two towers and a very big clock called Big Ben. Big Ben is really the bell which strikes every quarter of an hour. Opposite the Houses of Parliament is Westminster Abbey. Opposite the Houses of Parliament\\'s a very beautiful church built over 900 years ago. The tombs of many great statesmen, scientists and writers are there.\\n\\nTo the west of Westminster is West End. Here we find most of the big shops, hotels, museums, art galleries, theatres and concert halls. Picadilly Circus is the heart of London\\'s West End. In West End there are wide streets with beautiful houses and many parks, gardens and squares. To the east of Westminster is the East End, an industrial district of the capital. There are no parks or gardens in the East End and you can\\'t see many fine houses there. Most of the plants and factories are situated there. London has many places of interest. One of many places of interest is Buckingham Palace. It\\'s the residence of the Queen. The English are proud of Trafalgar Square, which was named so in memory of the victory at the battle. There in 1805 the English fleet defeated the fleet of France and Spain. The last place of interest I should like to mention, is the British Museum, the biggest museum in London. the British Museum, the biggest museum in London is famous for the British Museum, the biggest museum in London library -one of the richest in the world.\\n\\nAll London\\'s long-past history is told by All London\\'s long-past history streets. There are many streets in London which are known all over the\" world. Among many streets in London which are known all over the\" world Oxford Street, Downing Street and a lot of others can be mentioned. And tourists are usually attracted not only by the places of interest but by its streets too. In conclusion I should say if you are lucky enough to find yourself in London some day you will have a lot to see and enjoy there.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.coref_resolved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внимательный глаз заметит, что разрешение кореференций не идеально.\n",
    "\n",
    "Попробуем извлечь факты из нового текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resolving\n",
      "London / is / the capital of Great Britain, its political, economic and cultural centre\n",
      "\n",
      "After resolving\n",
      "London / is / the capital of Great Britain, London political, economic and cultural centre\n",
      "London / is / very old and beautiful\n",
      "London / is / the oldest part of London, London financial and business centre\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = neural_engine(text)\n",
    "resolved_doc = neural_engine(doc._.coref_resolved)  # Обработаем новый текст\n",
    "\n",
    "for document, label in zip([doc, resolved_doc], ['Before resolving', 'After resolving']):\n",
    "    statements = extract.semistructured_statements(document, \"London\")\n",
    "    print(label)\n",
    "    for statement in statements:\n",
    "        subject, verb, fact = statement\n",
    "        print(f\"{subject} / {verb} / {fact}\")\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого пара новых фактов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
