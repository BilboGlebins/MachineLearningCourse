{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обнаружение выбросов\n",
    "\n",
    "Выбросы - вещь неприятная, но, как правило, неизбежная. Сгенерируем данные с выбросами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(x):\n",
    "    return np.exp(-2 * x**2)\n",
    "\n",
    "\n",
    "def fit(x_fit, x_learn, y_learn, h=0.3):\n",
    "    distance = x_fit.reshape(-1, 1) - x_learn.reshape(1, -1)\n",
    "    weigths = K(distance / h)\n",
    "    yfit = np.sum(y_learn*weigths, axis=1) / np.sum(weigths, axis=1)\n",
    "    \n",
    "    return yfit\n",
    "\n",
    "h = 0.2\n",
    "np.random.seed(42)\n",
    "\n",
    "x = np.arange(0, 10, 0.1)\n",
    "y = np.sin(x) + np.cos(4*x)\n",
    "\n",
    "outlier_idx = np.random.choice(range(len(x)), 2, replace=False)\n",
    "x_noised = x + np.random.normal(0, 0.1, size=x.shape)\n",
    "y_noised = np.sin(x_noised) + np.cos(4*x_noised) + np.random.normal(0, 0.3, size=x.shape)\n",
    "y_noised[outlier_idx] *= 5\n",
    "\n",
    "xfit = np.arange(0, 10, 0.01)\n",
    "yfit = fit(xfit, x, y_noised, h)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.scatter(x, y_noised)\n",
    "plt.plot(xfit, yfit)\n",
    "plt.plot(x, y)\n",
    "_ = plt.title(f'h = {h}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скользящий контроль\n",
    "\n",
    "Автоматически выбросы можно определить при помощи метода скользящего контроля. Мы последовательно будем исключать из обучающей выборки по одной точке и смотреть, насколько будет изменяться ошибка аппроксимации на оставшейся части:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(x):\n",
    "    return np.exp(-2 * x**2)\n",
    "\n",
    "\n",
    "def fit(x_fit, x_learn, y_learn, h=0.3):\n",
    "    distance = x_fit.reshape(-1, 1) - x_learn.reshape(1, -1)\n",
    "    weigths = K(distance / h)\n",
    "    yfit = np.sum(y_learn*weigths, axis=1) / np.sum(weigths, axis=1)\n",
    "    \n",
    "    return yfit\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "h = 0.3\n",
    "\n",
    "x = np.arange(0, 10, 0.1)\n",
    "y = np.sin(x) + np.cos(4*x)\n",
    "\n",
    "x_noised = x + np.random.normal(0, 0.1, size=x.shape)\n",
    "y_noised = np.sin(x_noised) + np.cos(4*x_noised) + np.random.normal(0, 0.3, size=x.shape)\n",
    "\n",
    "outlier_idx = np.random.choice(range(len(x)), 2, replace=False)\n",
    "y_noised[outlier_idx] *= 5\n",
    "\n",
    "err = np.zeros_like(x)\n",
    "for i in range(x.size):\n",
    "    mask = np.ones_like(x, dtype=bool)\n",
    "    mask[i] = 0\n",
    "    \n",
    "    x_learn = x_noised[mask]\n",
    "    y_learn = y_noised[mask]\n",
    "    yfit = fit(x_learn, x_learn, y_learn, h)\n",
    "    \n",
    "    \n",
    "    err[i] = (np.sum(np.abs(yfit - y_learn)))\n",
    "\n",
    "_ = plt.hist(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что исключение пары точек значительно понижает ошибку аппроксимации. Вот и дотянемся до них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(x):\n",
    "    return np.exp(-2 * x**2)\n",
    "\n",
    "\n",
    "def fit(x_fit, x_learn, y_learn, h=0.3):\n",
    "    distance = x_fit.reshape(-1, 1) - x_learn.reshape(1, -1)\n",
    "    weigths = K(distance / h)\n",
    "    yfit = np.sum(y_learn*weigths, axis=1) / np.sum(weigths, axis=1)\n",
    "    \n",
    "    return yfit\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = np.arange(0, 10, 0.1)\n",
    "y = np.sin(x) + np.cos(4*x)\n",
    "\n",
    "outlier_idx = np.random.choice(range(len(x)), 2, replace=False)\n",
    "x_noised = x + np.random.normal(0, 0.1, size=x.shape)\n",
    "y_noised = np.sin(x_noised) + np.cos(4*x_noised) + np.random.normal(0, 0.3, size=x.shape)\n",
    "y_noised[outlier_idx] *= 5\n",
    "\n",
    "h = 0.3\n",
    "\n",
    "err = np.zeros_like(x)\n",
    "for i in range(x.size):\n",
    "    mask = np.ones_like(x, dtype=bool)\n",
    "    mask[i] = 0\n",
    "    \n",
    "    x_learn = x_noised[mask]\n",
    "    y_learn = y_noised[mask]\n",
    "    yfit = fit(x_learn, x_learn, y_learn, h)\n",
    "    \n",
    "    err[i] = (np.sum(np.abs(yfit - y_learn)))\n",
    "\n",
    "mask = np.ones_like(x, dtype=bool)\n",
    "outliers = np.argsort(err)[:2]\n",
    "mask[outliers] = 0\n",
    "\n",
    "xfit = np.arange(0, 10, 0.01)\n",
    "x_learn = x_noised[mask]\n",
    "y_learn = y_noised[mask]\n",
    "yfit = fit(xfit, x_learn, y_learn, h)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "plt.scatter(x[mask], y_noised[mask])\n",
    "plt.scatter(x[~mask], y_noised[~mask], marker='x', c='r', s=60)\n",
    "plt.plot(xfit, yfit, c='orange')\n",
    "_ = plt.plot(x, y, c='g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
