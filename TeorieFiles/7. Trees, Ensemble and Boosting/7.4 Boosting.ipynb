{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг\n",
    "Как и бэггинг, градиентный бустинг использует ансамбль слабых моделей чтобы получить сильную. Однако, есть пара важных отличий:\n",
    "1. При бустинге среди моделей проводится *взвешенное* голосование. В бэггинге веса не используются, все модели считаются равноправными.\n",
    "1. При бустинге ансамбль собирается *последовательно* и каждая следующая модель пытается учесть недостатки предыдущей\n",
    "\n",
    "Как добиться последнего? Базовые алгоритмы (составляющие ансамбль) на шаге T будут строиться путём минимизирования функционала качества по $\\alpha$ и $b$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Q(\\alpha, b) = \\sum_{i=1}^{l} \\mathcal{L}(\\sum_{t=1}^{T-1}\\alpha_t b_t(x_i) + \\alpha b(x_i), y_i)), (1)$$\n",
    "где $\\mathcal{L}$ - некоторая функция потерь.\n",
    "\n",
    "Однако, такая оптимизационная задача крайне нетривиальна. Применим тактическую хитрость. Давайте рассмотрим вектор ответов алгоритма на шаге $T-1$ на всех примерах обучающей выборки: \n",
    "\n",
    "$$u_{T-1} = (b(x_1), b(x_2), ... , b(x_l)), b(x) = \\sum_{t=1}^{T-1}\\alpha_t b_t(x)$$\n",
    "\n",
    "И рассмотреть эту задачу как $Q(u) = \\mathcal{L}(u, y) \\rightarrow \\min$. Градиентный метод оптимизации для решения этой задачи выглядит так:\n",
    "\n",
    "$$u_{T, i} = u_{T-1, i} - \\alpha g_i, (2)$$\n",
    "\n",
    "где $g_i = \\mathcal{L}^\\prime(u_{T-1, i}, y)$ - компоненты вектора градиента.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь самый важный момент - если взглянуть на формулы (1) и (2), то несложно понять, если $u_{T-1, i}$ это ни что иное как $\\sum_{t=1}^{T-1}\\alpha_t b_t(x)$, то выбор нового базового алгоритма $b(x_i)$ в (1) можно заменить градиентным шагом $g_i$ из (2).\n",
    "\n",
    "Иными словами, на каждом шаге будем искать такой базовый алгоритм $b_T$, чтобы вектор $u_{T} = (b_T(x_1), b_T(x_2), ... , b_T(x_l))$ приближал бы вектор антиградиента $-\\vec{g}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация в sklearn\n",
    "Разумеется, всё это уже реализовано до нас. Воспользуемся реализацией градиентного бустинга из библиотеки `sklearn.ensemble`. Там он лежит под именем `GradientBoostingRegressor` и создаётся примерно так же, как и `RandomForest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "titanic = titanic.drop(columns=['class', 'who', 'adult_male', 'embark_town', 'alive', 'alone'])\n",
    "titanic['deck'] = titanic['deck'].astype('str')\n",
    "titanic.loc[titanic['deck'].eq('nan'), 'deck'] = 'U'\n",
    "\n",
    "titanic['embarked'] = titanic['embarked'].astype('str')\n",
    "titanic.loc[titanic['embarked'].eq('nan'), 'embarked'] = 'U'\n",
    "\n",
    "titanic = titanic.dropna(subset=['age'])\n",
    "\n",
    "encoders = {}\n",
    "for column in titanic.columns:\n",
    "    if titanic[column].dtype == 'object':\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(titanic[column])\n",
    "        titanic[column] = encoder.transform(titanic[column])\n",
    "        encoders[column] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8053186250369349\n"
     ]
    }
   ],
   "source": [
    "def predict_by_booster(X_train, y_train, X_test, y_test):\n",
    "    tree = GradientBoostingClassifier(loss='deviance', \n",
    "                                      learning_rate=0.1,\n",
    "                                      n_estimators=10, \n",
    "                                      criterion='friedman_mse', \n",
    "                                      random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    predict = tree.predict(X_test)\n",
    "\n",
    "    acc = np.abs(predict == y_test).mean()\n",
    "    return acc\n",
    "\n",
    "titanic = titanic.sample(frac=1, replace=False, random_state=42)\n",
    "X = titanic.drop(columns=['survived'])\n",
    "y = titanic['survived'].copy()\n",
    "\n",
    "splits = np.linspace(0, y.size, 6)\n",
    "splits = splits.astype(int)\n",
    "\n",
    "acc = []\n",
    "\n",
    "for hi, low in zip(splits[:-1], splits[1:]):\n",
    "    train_mask = np.ones_like(y.values, dtype=bool)\n",
    "    train_mask[hi:low] = 0\n",
    "    test_mask = ~train_mask\n",
    "    \n",
    "    X_train, X_test = X[train_mask], X[test_mask]\n",
    "    y_train, y_test = y[train_mask], y[test_mask]\n",
    "    \n",
    "    acc.append(predict_by_booster(X_train, y_train, X_test, y_test))\n",
    "\n",
    "print(np.mean(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1nXOlrmVHqCHiixqiMF6H8LSciz583_W2#scrollTo=g7s7Grj-A-Sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализации градиентного бустинга"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
