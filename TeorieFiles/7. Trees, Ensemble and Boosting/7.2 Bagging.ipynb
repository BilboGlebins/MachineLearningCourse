{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ансамбли моделей\n",
    "\n",
    "Как мы уже увидели, деревья склонны переобучаться, что отрицательно сказывается на качестве конечной модели. Однако, слабые модели можно объединяться в ансамбли и выбирать среди них конечный ответ путём голосования. Так, комбинация простых моделей может выявлять более сложные зависимости. \n",
    "\n",
    "Возникает вопрос - как правильно комбинировать модели чтобы получать хорошие ансамбли? Хорошо зарекомендовавшим себя подходом является бэггинг. Своё название он берёт от принципа - **b**ootstrap **agg**regat**ing**. \n",
    "\n",
    "## Bootstrap\n",
    "\n",
    "Метод бутстрэпа заключается в создании обучающих подвыборок, путём выбора с возвращением. То есть, из обучающей выборки $X$ размера $N$ выберем $N$ объектов, однако, перед выбором следующего объекта, вернём выбранный объект обратно в обучающую выборку. Это как брать из мешка наугад шарик, а потом снова возвращать его обратно. Из-за этого в подвыборке окажутся повторы и она будет отличаться от исходной.\n",
    "\n",
    "Повторив процедуру $k$ раз, мы получим набор независимых подвыборок $X_1, X_2, ... , X_k$.\n",
    "\n",
    "## Bagging\n",
    "\n",
    "Имея в распоряжении набор независимых подвыборок $X_1, X_2, ... , X_k$, мы можем научить на каждой из них свой классификатор $a_1(X_1), a_2(X_2), ..., a_k(X_k)$. \n",
    "\n",
    "Причем необязательно это должны быть алгоритмы одного типа. Конечное же решение по классификации объекта будет принимать *итоговый классификатор*: \n",
    "$$a(x) = \\frac{1}{k}\\sum_{i=1}^{k}a_i(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Разумеется, бэггинг применим и к решающим деревьям. Набор (лес) деревьев учат на подвыборках, полученных бутстрэпом. Такой подход даже имеет собственное название *Random Forest*. \n",
    "\n",
    "Но Random Forest обладает ещё одной интересной особенностью - при построении очередного предиката учитываются не все признаки, а только их случайная выборка. Это делается для того, чтобы избежать однородности получающихся деревьев.\n",
    "\n",
    "Попробуем применить решающие деревья на практике и при помощи кросс-валидации сравнить результаты одного дерева, бэггинга и результаты работы случайного леса. В качестве обучающей выборки возьмём датасет titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание колонок:\n",
    "\n",
    "*  *survived* — поле в котором указано спасся человек (1) или нет (0)\n",
    "*  *pclass* — содержит социально-экономический статус: \n",
    "  * высокий \n",
    "  * средний\n",
    "  * низкий\n",
    "*  *sex* — пол пассажира\n",
    "*  *age* — возраст\n",
    "*  *sibsp* — содержит информацию о количестве родственников 2-го порядка (муж, жена, братья, сестры)\n",
    "*  *parch* — содержит информацию о количестве родственников на борту 1-го порядка (мать, отец, дети)\n",
    "*  *fare* — цена билета\n",
    "*  *Embarked* — порт посадки\n",
    "    * C — Cherbourg\n",
    "    * Q — Queenstown\n",
    "    * S — Southampton\n",
    "    \n",
    "    \n",
    "Дальше поля почему-то дублируют оставшиеся, кроме deck:\n",
    "*  *dect* — литера палубы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отбросим дублируемые колонки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "titanic = titanic.drop(\n",
    "    columns=['class', 'who', 'adult_male', 'embark_town', 'alive', 'alone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И поищем пропуски в данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isna().sum() / titanic.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И вот тут мы на распутье. Чем заполнять пропущенные значения? Если для палубы можно ввести дополнительную переменную, то как быть с возрастом? Начнём с палубы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['deck'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просто заполним пропуски литерой U (unknown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['deck'] = titanic['deck'].astype('str')\n",
    "titanic.loc[titanic['deck'].eq('nan'), 'deck'] = 'U'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же поступим с полем embarked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['embarked'] = titanic['embarked'].astype('str')\n",
    "titanic.loc[titanic['embarked'].eq('nan'), 'embarked'] = 'U'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот с возрастом всё не так просто. Очевидно, что возраст очень важная фича. И заполнять пропуски средним значением для 20% данных означет сильно запутать наш классификатор.\n",
    "\n",
    "А давайте совсем избавимся от них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.dropna(subset=['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полного счастья осталось сделать энкодинг признаков, потому, что дерево не станет работать с категориальными переменными. Для этого нам нужно закодировать признаки. В этом нам поможет `LabelEncoder` из библиотеки `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "for column in titanic.columns:\n",
    "    if titanic[column].dtype == 'object':\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(titanic[column])\n",
    "        titanic[column] = encoder.transform(titanic[column])\n",
    "        encoders[column] = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_tree(X_train, y_train, X_test, y_test):\n",
    "    tree = DecisionTreeClassifier(criterion='entropy',\n",
    "                                  random_state=42,\n",
    "                                  max_depth=None)\n",
    "    tree.fit(X_train, y_train)\n",
    "    predict = tree.predict(X_test)\n",
    "\n",
    "    return predict\n",
    "\n",
    "\n",
    "def predict_by_RF(X_train, y_train, X_test, y_test):\n",
    "    forest = RandomForestClassifier(n_estimators=100,\n",
    "                                    criterion='entropy',\n",
    "                                    random_state=42)\n",
    "    forest.fit(X_train, y_train)\n",
    "    predict = forest.predict(X_test)\n",
    "\n",
    "    return predict\n",
    "\n",
    "\n",
    "def accuracy(ans, pred):\n",
    "    acc = np.abs(pred == ans).mean() * 100\n",
    "    return acc\n",
    "\n",
    "\n",
    "X = titanic.drop(columns=['survived'])\n",
    "y = titanic['survived']\n",
    "\n",
    "np.random.seed(42)\n",
    "train_split = y.apply(lambda x: True if np.random.rand() < 0.8 else False)\n",
    "test_split = ~train_split\n",
    "\n",
    "X_train, X_test = X[train_split], X[test_split]\n",
    "y_train, y_test = y[train_split], y[test_split]\n",
    "\n",
    "tree_prediction = predict_by_tree(X_train, y_train, X_test, y_test)\n",
    "rf_prediction = predict_by_RF(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(f'Just one tree accuracy: {accuracy(y_test, tree_prediction):.2f}%')\n",
    "print(f'Random Forest accuracy: {accuracy(y_test, rf_prediction):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*N.B. Попробуйте поварьировать глубину дерева и критерий, чтобы посмотреть как меняются результаты*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И, чтобы быть уверенным в результатах, прокатим через кросс-валидацию:\n",
    "\n",
    "*N.B. Я надеюсь, что у вас выполнены ячейки выше и функции `predict_by_tree` и `predict_by_RF` определены*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.sample(frac=1, replace=False, random_state=42)\n",
    "X = titanic.drop(columns=['survived'])\n",
    "y = titanic['survived'].copy()\n",
    "\n",
    "splits = np.linspace(0, y.size, 6)\n",
    "splits = splits.astype(int)\n",
    "\n",
    "tree_acc = []\n",
    "rf_acc = []\n",
    "\n",
    "for hi, low in zip(splits[1:], splits[:-1]):\n",
    "    train_mask = np.ones_like(y.values, dtype=bool)\n",
    "    train_mask[low:hi] = 0\n",
    "    test_mask = ~train_mask\n",
    "\n",
    "    X_train, X_test = X[train_mask], X[test_mask]\n",
    "    y_train, y_test = y[train_mask], y[test_mask]\n",
    "\n",
    "    tree_prediction = predict_by_tree(X_train, y_train, X_test, y_test)\n",
    "    rf_prediction = predict_by_RF(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    tree_acc.append(accuracy(y_test, tree_prediction))\n",
    "    rf_acc.append(accuracy(y_test, rf_prediction))\n",
    "\n",
    "tree_mean_acc = np.mean(tree_acc)\n",
    "rf_mean_acc = np.mean(rf_acc)\n",
    "\n",
    "print(f'Just one tree cross-validation accuracy: {tree_mean_acc:.2f}%')\n",
    "print(f'Random Forest cross-validation accuracy: {rf_mean_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы предлагается сделать самостоятельно. Тем более, они должны зависеть от гиперпараметров моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение 1: Пара слов о метриках\n",
    "\n",
    "Количество выживших отличается от количество спасённых, а это делает наш датасет *несбалансированным*. А несбалансированный датасет это всегда плохо. \n",
    "- В смысле обучения: практически все модели будут отдавать предпочтения классам, которые встречаются чаще\n",
    "- В смысле оценки результатов: нужно быть осторожным с использованием простых метрик, вроде *accuracy*\n",
    "\n",
    "Меньше абстракции, больше живых примеров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = np.sum(titanic['survived'] == 1)\n",
    "drowned = np.sum(titanic['survived'] == 0)\n",
    "\n",
    "print(f'Количество выживших: {survived}')\n",
    "print(f'Количество утопленников (F): {drowned}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот проблема с метриками. Даже если объявить всех пассажиров утопленниками, `accuracy` будет выглядеть не так уж и плохо:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = titanic['survived']\n",
    "pred = np.zeros_like(ans)\n",
    "\n",
    "print(f'Cruel prediction accuracy: {accuracy(ans, pred):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь давайте посмотрим на другие метрики и сравним результаты с приличными предсказаниями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic.drop(columns=['survived'])\n",
    "y = titanic['survived']\n",
    "\n",
    "np.random.seed(42)\n",
    "train_split = y.apply(lambda x: True if np.random.rand() < 0.8 else False)\n",
    "test_split = ~train_split\n",
    "\n",
    "X_train, X_test = X[train_split], X[test_split]\n",
    "y_train, y_test = y[train_split], y[test_split]\n",
    "\n",
    "rf_prediction = predict_by_RF(X_train, y_train, X_test, y_test)\n",
    "skynet_prediction = np.zeros_like(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий пример показывает, что далеко не все метрики репрезентативны поодиночке. Например, [чувствительность и специфичность](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) хороши, но поодиночке могут вводить в заблуждение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepecifity_score(ans, pred):\n",
    "    TN, FP, FN, TP = confusion_matrix(ans, pred).ravel()\n",
    "    return TN / (TN + FP)\n",
    "\n",
    "\n",
    "def recall_score(ans, pred):\n",
    "    TN, FP, FN, TP = confusion_matrix(ans, pred).ravel()\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "\n",
    "sepecifity, skynet_sepecifity = sepecifity_score(\n",
    "    y_test, rf_prediction), sepecifity_score(y_test, skynet_prediction)\n",
    "recall, skynet_recall = recall_score(y_test, rf_prediction), recall_score(\n",
    "    y_test, skynet_prediction)\n",
    "\n",
    "print(f'Specifity: RF {sepecifity:.2f}  Skynet {skynet_sepecifity:.2f}')\n",
    "print(f'Recall:    RF {recall:.2f}  Skynet {skynet_recall:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаточно репрезентативной будет метрика `confusion matrix`. \n",
    "\n",
    "Это квадратная матрица со стороной, равной количеству классов в модели. Её строки соответствуют оценкам (то бишь, предсказаниям модели), а столбцы - правильным ответам. \n",
    "\n",
    "Элементы такой матрице соответствуют количеству семплов, которые были отнесены моделью в класс, равный номеру строки, и имеющие ответ, соответствующий столбцу.\n",
    "\n",
    "В нашем случае у нас получается матрица 2х2, Negatives - невыжившие, Positives - выжившие\n",
    "\n",
    "\\begin{bmatrix}\n",
    "    TN & FP \\\\\n",
    "    FN & TP\n",
    "\\end{bmatrix}\n",
    "\n",
    "- TN (true negatives): утонувшие люди, которые были классифицированы моделью как утонувшие\n",
    "- FP (false positives): утонувшие люди, которые были классифицированы моделью как спасшиеся\n",
    "- FN (false negatives): спасшиеся люди, которые были классифицированы моделью как утонувшие\n",
    "- TP (true positives): спасшиеся люди, которые были классифицированы моделью как спасшиеся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Памятка:')\n",
    "print('TN FP\\nFN TP\\n')\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, rf_prediction).ravel()\n",
    "print('Нормальная модель:')\n",
    "print(f'{TN} {FP}\\n{FN} {TP}\\n')\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, skynet_prediction).ravel()\n",
    "print('Модель с замашками скайнета:')\n",
    "print(f'{TN} {FP}\\n{FN} {TP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение 2: Важность признаков (коротенькое)\n",
    "\n",
    "Random Forest, бустеры и другие модели, которые являются композициями алгоритмов позволяют оценить *важность* каждого из признаков для принятия решений. \n",
    "\n",
    "Поскольку Random Forest усекает часть признаков когда строит различные деревья, можно оценить влияние каждого признака на конечный результат смотря на ошибку каждой из моделей. \n",
    "\n",
    "Информация о важности признаков хранится в атрибуте Random Forest модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic.drop(columns=['survived'])\n",
    "y = titanic['survived']\n",
    "\n",
    "np.random.seed(42)\n",
    "train_split = y.apply(lambda x: True if np.random.rand() < 0.8 else False)\n",
    "test_split = ~train_split\n",
    "\n",
    "X_train, X_test = X[train_split], X[test_split]\n",
    "y_train, y_test = y[train_split], y[test_split]\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100,\n",
    "                                criterion='entropy',\n",
    "                                random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(forest.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, важность признаков идёт без всяких подписей. Исправим это безобразие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = {\n",
    "    feature: importance\n",
    "    for feature, importance in zip(X_train.columns,\n",
    "                                   forest.feature_importances_)\n",
    "}\n",
    "\n",
    "for feature in sorted(importances, key=importances.get, reverse=True):\n",
    "    print(f'Importance of {feature}: {importances[feature]:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
