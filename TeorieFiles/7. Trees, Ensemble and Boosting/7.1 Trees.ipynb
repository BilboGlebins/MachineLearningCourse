{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cmap = 'Greens'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решающие деревья\n",
    "Рассмотрим ещё один алгоритм машинного обучения, преимущественно применяемого для классификации. Однако, при должном умении его можно применить и для регресии. Однако делать этого мы, конечно же, не будем.\n",
    "\n",
    "Решающие деревья появились как попытка формализовать принятие решений человеком. Например, при постановке врачом диагноза. Для постановки диагноза врач задаёт уточняющие вопросы, чтобы ограничить область возможных диагнозов. Прелесть такого подхода в том, что алгоритмы легко интерпретируются человеком.\n",
    "\n",
    "Сам алгоритм представляет собой дерево, в узлах которого находится некоторый предикат, в результате применения которого к признакам постепенно усекается пространство признаков до тех пор, пока в нём не окажутся объекты одного класса. Постараемся ответить на вопрос о том, как выбирать предикат.\n",
    "\n",
    "Пример взят [из курса ODS](https://habr.com/company/ods/blog/322534/#derevo-resheniy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для старта нам понадобится освежить в памяти понятие энтропии Шеннона. Для системы с N возможными состояниями формула выглядит как:\n",
    "$$S = -\\sum_{i=1}^{N}p_i \\log_2{p_i},$$\n",
    "где $p_i$ - вероятность нахождения системы в $i$-ом состоянии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, есть у нас вот такая последовательность шариков из двух цветов - 9 синих и 11 оранжевых.\n",
    "\n",
    "<img src=\"img/1.png\">\n",
    "\n",
    "Рассчитаем энтропию такой системы. Для наугад выбранного x вероятность вытащить синий шарик: $p_1 = \\frac{9}{20}$, а оранжевый: $p_2 = \\frac{11}{20}$. Посчитаем энтропию такой системы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 9 / 20\n",
    "p2 = 11 / 20\n",
    "\n",
    "S = -p1 * np.log2(p1) - p2 * np.log2(p2)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разобьём выборку на две по порогу $x \\le 12$:\n",
    "\n",
    "<img src=\"img/2.png\">\n",
    "\n",
    "А теперь посчитаем энтропию для каждой из выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p11 = 8 / 13\n",
    "p12 = 5 / 13\n",
    "\n",
    "p21 = 1 / 7\n",
    "p22 = 6 / 7\n",
    "\n",
    "S1 = -p11 * np.log2(p11) - p12 * np.log2(p12)\n",
    "S2 = -p21 * np.log2(p21) - p22 * np.log2(p22)\n",
    "\n",
    "print(S1, S2)\n",
    "print(np.mean([S1, S2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот мы и подошли к правилу: \n",
    "> Разбив исходный набор данных на две части по некому предикату, можно рассчитать энтропию каждого подмножества, после чего рассчитать среднее значение энтропии — если оно окажется меньшим чем энтропия исходного множества, значит предикат содержит некую обобщающую информацию о данных.\n",
    "\n",
    "Следовательно, нужно выбирать такие предикаты, которые несут наибольшее падение энтропии. Выберем разбиение, которое даст минимум средней энтропии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balls = np.array([0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "                 dtype=bool)\n",
    "mean = []\n",
    "for split in range(1, len(balls) - 1):\n",
    "    p12 = np.sum(balls[:split]) / balls[:split].size\n",
    "    p11 = 1 - p12\n",
    "\n",
    "    p22 = np.sum(balls[split:]) / balls[split:].size\n",
    "    p21 = 1 - p22\n",
    "\n",
    "    S1 = -p11 * np.log2(p11) - p12 * np.log2(p12)\n",
    "    S2 = -p21 * np.log2(p21) - p22 * np.log2(p22)\n",
    "\n",
    "    mean.append(np.mean([S1, S2]))\n",
    "\n",
    "plt.plot(mean)\n",
    "_ = plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот мы и видим, что разбиение по 12 было выбранно неспроста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Критерий Джини\n",
    "\n",
    "Энтропийный критерий - далеко не единственный. Более того, в реализации решающих деревьев библиотеки `sklearn` по умолчанию используется критерий Джини. \n",
    "\n",
    "Изначально критерий Джини был статистический показатель степени расслоения общества данной страны или региона по отношению к какому-либо изучаемому признаку. Вычисляется как отношение площади фигуры, образованной кривой Лоренца и кривой равенства, к площади треугольника, образованного кривыми равенства и неравенства. Подробнее об этом можно почитать в [англоязычной вики](https://en.wikipedia.org/wiki/Gini_coefficient), ибо в русскоязычной статья неприлично куцая.\n",
    "\n",
    "Более интуитивная формулировка: численное значение критерия Джини есть *вероятность неправильной классификации*, если предсказывать классы с вероятностями их появления в этом узле.\n",
    "\n",
    "В конце тетрадки будет визуализация дерева с количественным значением критерия Джини в каждом узле. Это должно закрепить интуитивное понимания его численного значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика\n",
    "\n",
    "Выполним задачу классификации ирисов Фишера используя решающие деревья. Для начала, вспомним как выглядят данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "X = iris[['petal_width', 'petal_length']].values\n",
    "y = iris.species.copy()\n",
    "\n",
    "for i, species in enumerate(iris.species.unique()):\n",
    "    y.loc[y.eq(species)] = i\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, edgecolors='k')\n",
    "plt.xlabel('Ширина лепестка')\n",
    "plt.ylabel('Длина лепестка')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся реализацией решающего дерева из библиотеки `sklearn.tree`. Класс называется `DecisionTreeClassifier`.\n",
    "\n",
    "Воспользуемся парамтерами:\n",
    "* `criterion='entropy'` - чтобы критерием построения предиката выступало уменьшение энтропии\n",
    "* `max_depth=1` - глубина дерева, т.е. количество предикатов. Будем увеличивать.\n",
    "* `random_state=42` - для воспроизводимости результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Напишем вспомогательную функцию, которая будет возвращать решетку для дальнейшей визуализации.\n",
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                       np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "X = iris[['petal_width', 'petal_length']].values\n",
    "y = iris.species.copy()\n",
    "\n",
    "for i, species in enumerate(iris.species.unique()):\n",
    "    y.loc[y.eq(species)] = i\n",
    "\n",
    "# немного кода для отображения разделяющей поверхности\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "xx, yy = get_grid(X)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    max_depth = i + 1\n",
    "\n",
    "    clf_tree = DecisionTreeClassifier(criterion='entropy',\n",
    "                                      max_depth=max_depth,\n",
    "                                      random_state=42)\n",
    "    clf_tree.fit(X, y)\n",
    "\n",
    "    predicted = clf_tree.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(\n",
    "        xx.shape)\n",
    "\n",
    "    ax.pcolormesh(xx, yy, predicted, cmap=cmap, alpha=0.1,\n",
    "                  shading='gouraud')  # cmap определён в самой первой ячейке\n",
    "    ax.scatter(X[:, 0],\n",
    "               X[:, 1],\n",
    "               c=y,\n",
    "               cmap=cmap,\n",
    "               edgecolors='black',\n",
    "               linewidth=1.5)\n",
    "    ax.set_title(f'max depth = {max_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь позволим дереву переобучиться:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Напишем вспомогательную функцию, которая будет возвращать решетку для дальнейшей визуализации.\n",
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                       np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "X = iris[['petal_width', 'petal_length']].values\n",
    "y = iris.species.copy()\n",
    "\n",
    "for i, species in enumerate(iris.species.unique()):\n",
    "    y.loc[y.eq(species)] = i\n",
    "\n",
    "xx, yy = get_grid(X)\n",
    "\n",
    "entorpy_tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "gini_tree = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "\n",
    "entorpy_tree.fit(X, y)\n",
    "gini_tree.fit(X, y)\n",
    "\n",
    "ctiterion = 'entropy'\n",
    "if ctiterion == 'entropy':\n",
    "    classifier = entorpy_tree\n",
    "elif ctiterion == 'gini':\n",
    "    classifier = gini_tree\n",
    "\n",
    "predicted = classifier.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.pcolormesh(xx, yy, predicted, cmap=cmap, alpha=0.1, shading='gouraud')\n",
    "plt.scatter(X[:, 0],\n",
    "            X[:, 1],\n",
    "            c=y,\n",
    "            cmap=cmap,\n",
    "            edgecolors='black',\n",
    "            linewidth=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что плохого? А давайте отрежем 20% данных для обучения, обучим на них и посмотрим, как поведёт себя дерево:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Напишем вспомогательную функцию, которая будет возвращать решетку для дальнейшей визуализации.\n",
    "def get_grid(data):\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                       np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "iris = iris.sample(frac=1, replace=False, random_state=42)\n",
    "\n",
    "X = iris[['petal_width', 'petal_length']].values\n",
    "y = iris.species.copy()\n",
    "\n",
    "split = int(y.size * 0.8)\n",
    "\n",
    "for i, species in enumerate(iris.species.unique()):\n",
    "    y.loc[y.eq(species)] = i\n",
    "\n",
    "xx, yy = get_grid(X)\n",
    "\n",
    "entorpy_tree = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "gini_tree = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "\n",
    "entorpy_tree.fit(X[:split], y[:split])\n",
    "gini_tree.fit(X[:split], y[:split])\n",
    "\n",
    "ctiterion = 'entropy'\n",
    "if ctiterion == 'entropy':\n",
    "    classifier = entorpy_tree\n",
    "elif ctiterion == 'gini':\n",
    "    classifier = gini_tree\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "predicted = classifier.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "plt.pcolormesh(xx,\n",
    "               yy,\n",
    "               predicted,\n",
    "               cmap=cmap,\n",
    "               alpha=0.1,\n",
    "               edgecolors=None,\n",
    "               shading='gouraud')\n",
    "plt.scatter(X[:, 0],\n",
    "            X[:, 1],\n",
    "            c=y,\n",
    "            cmap=cmap,\n",
    "            edgecolors='black',\n",
    "            linewidth=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что дерево переобучилось. О том, что с этим делать мы разберёмся дальше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация решающих деревьев\n",
    "\n",
    "Какое главное достоинство решающих деревьев? Их интерпретируемость! Мы всегда можем проследить логику принятия решения. Как? Можно визуализировать все вершины, которые содержат предикаты.\n",
    "\n",
    "Чтобы построить вершины обученного дерева нужно воспользоваться пакетом `graphviz`.\n",
    "\n",
    "*N.B. Возможно, на голой анаконде этот код не запустится. Попробуйте поставить модуль* `graphviz` *отдельно. Курите конда преферанс*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант с энтропией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = tree.export_graphviz(entorpy_tree, out_file=None)\n",
    "graph = graphviz.Source(nodes)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На случай если не выйдет (или лениво) поставить `graphviz`, прикрепляю граф дерева в виде картинки\n",
    "<img src=\"img/entropy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант с критерием Джини"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = tree.export_graphviz(gini_tree, out_file=None)\n",
    "graph = graphviz.Source(nodes)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И снова в виде пикчи:\n",
    "<img src=\"img/gini.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
